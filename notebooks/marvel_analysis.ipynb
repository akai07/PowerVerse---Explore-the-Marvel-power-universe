{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marvel Universe: Character Analysis\n",
    "\n",
    "This notebook analyzes the Marvel character dataset to explore powers, roles, and affiliations using various data science techniques.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "1. Explore and clean the dataset\n",
    "2. Perform NLP on character powers\n",
    "3. Predict character roles based on powers\n",
    "4. Cluster similar characters\n",
    "5. Create network visualizations of character affiliations\n",
    "6. Estimate power levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import networkx as nx\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import spacy\n",
    "\n",
    "# Set plotting style\n",
    "sns.set(style='whitegrid')\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "# Display settings\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('../data/marvel_characters_dataset.csv')\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about the dataset\n",
    "print(f'Dataset shape: {df.shape}')\n",
    "df.info()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "# Convert all character names to title case for consistency\n",
    "df['Character'] = df['Character'].str.title()\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df[df.duplicated('Character')]\n",
    "print(f'Number of duplicate characters: {len(duplicates)}')\n",
    "if len(duplicates) > 0:\n",
    "    print(duplicates)\n",
    "    # Remove duplicates if needed\n",
    "    df = df.drop_duplicates('Character')\n",
    "\n",
    "# Standardize role categories\n",
    "df['Role'] = df['Role'].str.title()\n",
    "\n",
    "# Display cleaned data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of roles\n",
    "plt.figure(figsize=(10, 6))\n",
    "role_counts = df['Role'].value_counts()\n",
    "sns.barplot(x=role_counts.index, y=role_counts.values)\n",
    "plt.title('Distribution of Character Roles', fontsize=16)\n",
    "plt.xlabel('Role')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Pie chart of roles\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(role_counts, labels=role_counts.index, autopct='%1.1f%%', startangle=90, colors=sns.color_palette('viridis', len(role_counts)))\n",
    "plt.title('Proportion of Character Roles', fontsize=16)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of affiliations\n",
    "plt.figure(figsize=(12, 8))\n",
    "affiliation_counts = df['Affiliation'].value_counts().head(10)  # Top 10 affiliations\n",
    "sns.barplot(x=affiliation_counts.values, y=affiliation_counts.index)\n",
    "plt.title('Top 10 Character Affiliations', fontsize=16)\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Affiliation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Analysis with NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word cloud of powers\n",
    "all_powers = ' '.join(df['Powers'].dropna())\n",
    "\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=100, contour_width=3, contour_color='steelblue').generate(all_powers)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Marvel Character Powers', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization of powers\n",
    "tfidf = TfidfVectorizer(stop_words='english', min_df=2)\n",
    "powers_tfidf = tfidf.fit_transform(df['Powers'].fillna(''))\n",
    "\n",
    "# Get feature names\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "\n",
    "# Display the top terms for each character\n",
    "def display_top_terms(character_idx, top_n=5):\n",
    "    character_name = df.iloc[character_idx]['Character']\n",
    "    tfidf_scores = powers_tfidf[character_idx].toarray()[0]\n",
    "    top_indices = tfidf_scores.argsort()[-top_n:][::-1]\n",
    "    top_terms = [(feature_names[i], tfidf_scores[i]) for i in top_indices]\n",
    "    print(f'Top terms for {character_name}:')\n",
    "    for term, score in top_terms:\n",
    "        print(f'  - {term}: {score:.4f}')\n",
    "\n",
    "# Display top terms for a few characters\n",
    "for idx in [0, 5, 10]:  # Iron Man, Spider-Man, Scarlet Witch\n",
    "    display_top_terms(idx)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster characters based on powers using K-means\n",
    "n_clusters = 5  # You can adjust this\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(powers_tfidf)\n",
    "\n",
    "# Visualize clusters\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce dimensions for visualization\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "powers_2d = pca.fit_transform(powers_tfidf.toarray())\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "plot_df = pd.DataFrame({\n",
    "    'x': powers_2d[:, 0],\n",
    "    'y': powers_2d[:, 1],\n",
    "    'character': df['Character'],\n",
    "    'role': df['Role'],\n",
    "    'cluster': df['Cluster']\n",
    "})\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=plot_df, x='x', y='y', hue='cluster', style='role', s=100)\n",
    "\n",
    "# Add character labels\n",
    "for i, row in plot_df.iterrows():\n",
    "    plt.annotate(row['character'], (row['x'], row['y']), fontsize=8)\n",
    "\n",
    "plt.title('Character Clusters Based on Powers', fontsize=16)\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict character role based on powers\n",
    "X = powers_tfidf\n",
    "y = df['Role']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print('Classification Report:\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=rf.classes_, yticklabels=rf.classes_)\n",
    "plt.title('Confusion Matrix', fontsize=16)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict role from powers\n",
    "def predict_role(powers_text):\n",
    "    # Transform the input text\n",
    "    powers_vector = tfidf.transform([powers_text])\n",
    "    \n",
    "    # Make prediction\n",
    "    predicted_role = rf.predict(powers_vector)[0]\n",
    "    probabilities = rf.predict_proba(powers_vector)[0]\n",
    "    \n",
    "    # Get probability for each class\n",
    "    proba_dict = {role: prob for role, prob in zip(rf.classes_, probabilities)}\n",
    "    \n",
    "    return predicted_role, proba_dict\n",
    "\n",
    "# Test with some examples\n",
    "test_powers = [\n",
    "    \"Superhuman strength, Flight, Energy projection\",\n",
    "    \"Mind control, Telekinesis, Illusion creation\",\n",
    "    \"Regeneration, Enhanced senses, Combat skills\"\n",
    "]\n",
    "\n",
    "for powers in test_powers:\n",
    "    role, probas = predict_role(powers)\n",
    "    print(f'Powers: {powers}')\n",
    "    print(f'Predicted Role: {role}')\n",
    "    print('Probabilities:')\n",
    "    for role, prob in sorted(probas.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f'  - {role}: {prob:.2f}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affiliation Network Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a network graph of characters based on shared affiliations\n",
    "G = nx.Graph()\n",
    "\n",
    "# Add nodes (characters)\n",
    "for idx, row in df.iterrows():\n",
    "    G.add_node(row['Character'], role=row['Role'], affiliation=row['Affiliation'])\n",
    "\n",
    "# Add edges (shared affiliations)\n",
    "affiliations = df['Affiliation'].unique()\n",
    "for affiliation in affiliations:\n",
    "    chars_in_affiliation = df[df['Affiliation'] == affiliation]['Character'].tolist()\n",
    "    for i in range(len(chars_in_affiliation)):\n",
    "        for j in range(i+1, len(chars_in_affiliation)):\n",
    "            G.add_edge(chars_in_affiliation[i], chars_in_affiliation[j], affiliation=affiliation)\n",
    "\n",
    "# Visualize the network\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Set node colors based on role\n",
    "role_colors = {'Hero': 'blue', 'Villain': 'red', 'Antihero': 'purple'}\n",
    "node_colors = [role_colors.get(G.nodes[node]['role'], 'gray') for node in G.nodes()]\n",
    "\n",
    "# Set node sizes based on degree (number of connections)\n",
    "node_sizes = [300 * (1 + G.degree(node)) for node in G.nodes()]\n",
    "\n",
    "# Draw the network\n",
    "pos = nx.spring_layout(G, seed=42)  # Position nodes using force-directed layout\n",
    "nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, alpha=0.8)\n",
    "nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5)\n",
    "nx.draw_networkx_labels(G, pos, font_size=10, font_weight='bold')\n",
    "\n",
    "# Add a legend\n",
    "import matplotlib.patches as mpatches\n",
    "legend_patches = [mpatches.Patch(color=color, label=role) for role, color in role_colors.items()]\n",
    "plt.legend(handles=legend_patches, title='Character Role')\n",
    "\n",
    "plt.title('Marvel Character Affiliation Network', fontsize=20)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Level Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to estimate power level based on powers\n",
    "def estimate_power_level(powers_text):\n",
    "    # Define power keywords for each level\n",
    "    high_power_keywords = ['cosmic', 'reality', 'god', 'manipulation', 'telekinesis', 'magic', 'energy projection']\n",
    "    medium_power_keywords = ['superhuman strength', 'regeneration', 'flight', 'enhanced', 'super', 'control']\n",
    "    \n",
    "    powers_lower = powers_text.lower()\n",
    "    \n",
    "    # Check for high power keywords\n",
    "    for keyword in high_power_keywords:\n",
    "        if keyword in powers_lower:\n",
    "            return 'High'\n",
    "    \n",
    "    # Check for medium power keywords\n",
    "    for keyword in medium_power_keywords:\n",
    "        if keyword in powers_lower:\n",
    "            return 'Medium'\n",
    "    \n",
    "    # Default to low\n",
    "    return 'Low'\n",
    "\n",
    "# Apply the function to estimate power levels\n",
    "df['Estimated_Power_Level'] = df['Powers'].apply(estimate_power_level)\n",
    "\n",
    "# Display the distribution of estimated power levels\n",
    "plt.figure(figsize=(10, 6))\n",
    "power_level_counts = df['Estimated_Power_Level'].value_counts().sort_index()\n",
    "sns.barplot(x=power_level_counts.index, y=power_level_counts.values, palette='viridis')\n",
    "plt.title('Distribution of Estimated Power Levels', fontsize=16)\n",
    "plt.xlabel('Power Level')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Compare power levels across roles\n",
    "plt.figure(figsize=(12, 8))\n",
    "role_power_counts = pd.crosstab(df['Role'], df['Estimated_Power_Level'])\n",
    "role_power_counts.plot(kind='bar', stacked=True, colormap='viridis')\n",
    "plt.title('Power Level Distribution by Role', fontsize=16)\n",
    "plt.xlabel('Role')\n",
    "plt.ylabel('Count')\n",
    "plt.legend(title='Power Level')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Processed Data for React App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the processed data with estimated power levels\n",
    "df.to_csv('../data/processed_marvel_characters.csv', index=False)\n",
    "\n",
    "# Export network data for visualization in React\n",
    "# Nodes\n",
    "nodes_data = []\n",
    "for node in G.nodes():\n",
    "    nodes_data.append({\n",
    "        'id': node,\n",
    "        'role': G.nodes[node]['role'],\n",
    "        'affiliation': G.nodes[node]['affiliation'],\n",
    "        'power_level': df[df['Character'] == node]['Estimated_Power_Level'].values[0]\n",
    "    })\n",
    "\n",
    "# Edges\n",
    "edges_data = []\n",
    "for source, target, data in G.edges(data=True):\n",
    "    edges_data.append({\n",
    "        'source': source,\n",
    "        'target': target,\n",
    "        'affiliation': data['affiliation']\n",
    "    })\n",
    "\n",
    "# Save to JSON\n",
    "import json\n",
    "\n",
    "network_data = {\n",
    "    'nodes': nodes_data,\n",
    "    'links': edges_data\n",
    "}\n",
    "\n",
    "with open('../data/marvel_network.json', 'w') as f:\n",
    "    json.dump(network_data, f, indent=2)\n",
    "\n",
    "print('Data exported successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've analyzed the Marvel character dataset using various data science techniques:\n",
    "\n",
    "1. Explored and cleaned the dataset\n",
    "2. Performed NLP analysis on character powers\n",
    "3. Clustered characters based on their powers\n",
    "4. Built a model to predict character roles\n",
    "5. Created a network visualization of character affiliations\n",
    "6. Estimated power levels based on character abilities\n",
    "\n",
    "The processed data and visualizations can now be used in the React frontend application to create an interactive experience for exploring the Marvel universe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}